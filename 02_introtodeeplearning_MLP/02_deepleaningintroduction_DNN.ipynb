{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "<a href=\"https://colab.research.google.com/github/marcoteran/deeplearningmodule/blob/main/01_unsupervisedlearning_kmeans/01_unsupervisedlearning_kmeans.ipynb\" target=\"_blank\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\" title=\"Abrir y ejecutar en Google Colaboratory\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de código\n",
    "# Introducción al Aprendizaje profundo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Name:* Marco Teran\n",
    "*E-mail:* marco.tulio.teran@gmail.com,\n",
    "[Website](http://marcoteran.github.io/),\n",
    "[Github](https://github.com/marcoteran),\n",
    "[LinkedIn](https://www.linkedin.com/in/marcoteran/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar librerías importantes\n",
    "\n",
    "Empezamos con las importaciones estándar para visualizar los datos y recrear las superficies de decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns; sns.set()  # for plot styling\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering, DBSCAN\n",
    "from IPython.display import HTML\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "\n",
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurona artificial\n",
    "\n",
    "<img src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/6/60/ArtificialNeuronModel_english.png/600px-ArtificialNeuronModel_english.png\" >\n",
    "\n",
    "* El perceptrón es un algoritmo de clasificación que genera una predicción para una entrada $(x)$ de la siguiente manera:\n",
    "$$\\textrm{Predicción}(x)=\\begin{cases}\n",
    "C_{1} & \\mbox{si }f(x)\\ge \\theta\\\\\n",
    "C_{2} & \\mbox{si }f(x)<\\theta\n",
    "\\end{cases}$$\n",
    "\n",
    "* De igual forma, $f(x)$ está definida como una suma ponderada sobre los elementos de la entrada:\n",
    "$$\n",
    "f(x) = w_0 + \\sum_{i=1}^{n} {w_i x_i}\n",
    "$$\n",
    "dónde $x$ corresponde a la entrada, $w$ corresponde a los pesos que se multiplican por la entrada $x$ y $w_0$ al sesgo.\n",
    "\n",
    "* Para poder generar $\\textrm{Predicción}(x)$, se toma la salida de $f(x)$ y se le aplica una **función de activación** $\\varphi$. Así la salida del perceptrón es de la siguiente forma:\n",
    "$$\n",
    "y = \\varphi(w_0 + \\sum_{i=1}^{n} {w_i x_i})\n",
    "$$\n",
    "\n",
    "* Es común encontrar en la literatura que se mencione que una neurona se activó, si su valor de la salida $y$ superó el umbral $\\theta$ definido para la neurona.\n",
    "\n",
    "**¿Cómo escoger $\\varphi$?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de activación de paso\n",
    "\n",
    "El caso más sencillo se conoce como la función de activación de paso. La función de activación de paso se define de la siguiente manera:\n",
    "\n",
    "$$\\textrm{H}(x)=\\begin{cases}\n",
    "0 & \\mbox{si }x\\ge \\theta\\\\\n",
    "1 & \\mbox{si }x<\\theta\n",
    "\\end{cases}$$\n",
    "\n",
    "La cual observamos a continuación\n",
    "\n",
    "<img src=\"https://c.mql5.com/2/4/act1.png\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de activación logística\n",
    "\n",
    "La función de activación logística está basada en la función sigmoide $\\sigma$. La función sigmoíde para cualquier valor $z$ se define de la siguiente manera:\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1 - e^{-z}}$$\n",
    "\n",
    "<img width= 300 src=\"http://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/SigmoidFunction.png/400px-SigmoidFunction.png\" align=\"middle\">\n",
    "\n",
    "Cómo se puede observar en la imagen, la función sigmoide genera valores entre $0$ y $1$. A diferencia de la función de activación de paso, la sigmoide genera una transición entre $0$ y $1$. La salida del perceptrón queda definida de la siguiente manera:\n",
    "\n",
    "$$\n",
    "y = \\sigma(w_0 + \\sum_{i=1}^{n} {w_i x_i})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 1: El Hello World del Deep Learning con Redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en cada primera aplicación, deberías empezar con algo super simple que muestre el andamiaje general de cómo funciona tu código. \n",
    "\n",
    "En el caso de la creación de redes neuronales, la muestra que me gusta usar es una en la que se aprende la relación entre dos números. Así, por ejemplo, si estuvieras escribiendo código para una función como esta, ya conoces las \"reglas\" - \n",
    "\n",
    "```\n",
    "float hw_function(float x){\n",
    "    float y = (2 * x) - 1;\n",
    "    return y;\n",
    "}\n",
    "```\n",
    "Entonces, ¿cómo entrenarías a una red neuronal para hacer la tarea equivalente? ¡Usando datos! Alimentándola con un conjunto de Xs, y un conjunto de Ys, debería ser capaz de averiguar la relación entre ellos. \n",
    "\n",
    "Obviamente, este es un paradigma muy diferente al que podrías estar acostumbrado, así que vamos a repasarlo pieza por pieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir y compilar la red neuronal\n",
    "\n",
    "A continuación crearemos la red neuronal más simple posible. Tiene una capa, y esa capa tiene una neurona, y la forma de entrada a ella es sólo un valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora compilamos nuestra Red Neural. Cuando lo hacemos, tenemos que especificar 2 funciones, una función de pérdida y un optimizador.\n",
    "\n",
    "Si has visto muchas matemáticas para el aprendizaje de la máquina, aquí es donde se utiliza normalmente, pero en este caso está bien encapsulado en funciones para ti. Pero lo que sucede aquí - vamos a explicar...\n",
    "\n",
    "Sabemos que en nuestra función, la relación entre los números es y=2x-1. \n",
    "\n",
    "Cuando la computadora está tratando de \"aprender\" eso, hace una suposición... tal vez y=10x+10. La función PÉRDIDA mide las respuestas adivinadas contra las respuestas correctas conocidas y mide qué tan bien o qué tan mal lo hizo.\n",
    "\n",
    "Luego usa la función OPTIMIZADOR para hacer otra suposición. Basándose en cómo fue la función de pérdida, intentará minimizar la pérdida. En ese punto, tal vez se le ocurra algo como y=5x+5, que, aunque sigue siendo bastante malo, está más cerca del resultado correcto (es decir, la pérdida es menor)\n",
    "\n",
    "Lo repetirá para el número de EPOCHS que verá en breve. Pero primero, así es como le decimos que use \"ERROR CUADRADO MEDIO\" para la pérdida y \"DESCENSO GRADIANTE ESTÓSTICO\" para el optimizador. No necesitas entender las matemáticas para esto todavía, ¡pero puedes ver que funcionan! :)\n",
    "\n",
    "Con el tiempo aprenderás las diferentes y apropiadas funciones de pérdida y optimizador para diferentes escenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proveyendo los datos\n",
    "\n",
    "A continuación, alimentaremos algunos datos. En este caso estamos tomando 6 x y 6ys. Puedes ver que la relación entre estos es que y=2x-1, así que donde x = -1, y=-3 etc. etc. \n",
    "\n",
    "Una biblioteca de pitón llamada 'Numpy' proporciona un montón de estructuras de datos de tipo matriz que son una forma estándar de hecho de hacerlo. Declaramos que queremos usarlas especificando los valores como un np.array[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenando la Red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de entrenamiento de la red neuronal, donde \"aprende\" la relación entre los X y los Y está en la llamada **model.fit**. Aquí es donde pasará por el bucle del que hablamos anteriormente, haciendo una suposición, midiendo lo bueno o lo malo que es (también conocido como la pérdida), usando el opimizador para hacer otra suposición, etc. Lo hará para el número de épocas que especifiques. Cuando ejecute este código, verá la pérdida en el lado derecho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(xs, ys, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, ahora tienes un modelo que ha sido entrenado para aprender la relación entre X e Y. Puedes usar el método **model.predict** para que descubra el Y de un X previamente desconocido. Así, por ejemplo, si X = 10, ¿qué crees que será Y? Adivina antes de ejecutar este código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podrías haber pensado en el 19, ¿verdad? Pero terminó siendo un poco menos. ¿Por qué crees que es así? \n",
    "\n",
    "Recuerda que las redes neuronales tratan con probabilidades, así que dados los datos con los que alimentamos a los NN, calculó que hay una probabilidad muy alta de que la relación entre X e Y sea Y=2X-1, pero con sólo 6 puntos de datos no podemos saberlo con seguridad. Como resultado, el resultado para 10 es muy cercano a 19, pero no necesariamente 19. \n",
    "\n",
    "A medida que trabajes con redes neuronales, verás que este patrón se repite. Casi siempre tratará con probabilidades, no certezas, y hará un poco de codificación para averiguar cuál es el resultado basado en las probabilidades, particularmente cuando se trata de la clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 2: Clasificador de digitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# helps us to represent our data as lists easily and quickly\n",
    "import numpy as np\n",
    "# framework for defining a neural network as a set of Sequential layers\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos del MNIST están disponibles directamente en el API de los conjuntos de datos de tf.keras. Lo cargas así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[8], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver la etiqueta\n",
    "print(y_train[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_slice = x_train[0:100,:]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_slice = x_train[:,7:-7,7:-7]\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado de datos de entrada en una red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train/=255\n",
    "x_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_rs = x_train.reshape(60000,784)\n",
    "x_test_rs = x_test.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_rs.shape)\n",
    "print(x_test_rs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuración del proceso de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train_rs, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "test_loss, test_acc = model.evaluate(x_test_rs, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[11], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(predictions[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(predictions[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo 3: Redes neuronales en Keras: Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echemos un vistazo a un escenario en el que podemos reconocer diferentes prendas de vestir, entrenadas a partir de un conjunto de datos que contiene 10 tipos diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos del MNIST de la moda están disponibles directamente en el API de los conjuntos de datos de tf.keras. Lo cargas así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamar a load_data en este objeto le dará dos conjuntos de dos listas, estos serán los valores de entrenamiento y prueba para los gráficos que contienen las prendas de vestir y sus etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga de datos\n",
    "(training_images, training_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser/pants', 'Pullover shirt', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo son estos valores? Imprimamos una imagen de entrenamiento, y una etiqueta de entrenamiento para ver... Experimentemos con diferentes índices en la matriz. Por ejemplo, mira también el índice 42... que es una bota diferente a la del índice 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(training_images[0])\n",
    "print(training_labels[0])\n",
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notarán que todos los valores del número están entre 0 y 255. Si estamos entrenando una red neuronal, por varias razones es más fácil si tratamos todos los valores entre 0 y 1, un proceso llamado '**normalizar**'... y afortunadamente en Python es fácil normalizar una lista como esta sin hacer un bucle. Lo haces así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = training_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "\n",
    "training_images /= 255\n",
    "test_images /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se preguntarán por qué hay dos grupos... entrenamiento y pruebas... ¿Recuerdan que hablamos de esto en la introducción? La idea es tener un conjunto de datos para el entrenamiento, y luego otro conjunto de datos... que el modelo aún no ha visto... para ver lo bueno que sería para clasificar los valores. Después de todo, cuando termines, ¡vas a querer probarlo con datos que no había visto antes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_images.shape: \", training_images.shape)\n",
    "print(\"len(train_labels): \", len(training_labels))\n",
    "print(\"test_images.shape: \", test_images.shape)\n",
    "print(\"len(test_labels): \", len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "for i in range(50):\n",
    "    plt.subplot(10, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(training_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[training_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora diseñemos el modelo. Hay bastantes conceptos nuevos aquí, pero no te preocupes, les cogerás el tranquillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(keras.layers.Dense(10, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequential**: Eso define una SECUENCIA de capas en la red neuronal\n",
    "\n",
    "**Flatten**: ¿Recuerdas antes cuando nuestras imágenes eran un cuadrado, cuando las imprimiste? Flatten sólo toma ese cuadrado y lo convierte en un conjunto de una dimensión.\n",
    "\n",
    "**Dense**: Añade una capa de neuronas\n",
    "\n",
    "Cada capa de neuronas necesita una función de activación para decirles qué hacer. Hay muchas opciones, pero por ahora sólo úsalas. \n",
    "\n",
    "**Relu** significa efectivamente \"Si X>0 devuelve X, si no devuelve 0\" -- así que lo que hace es pasar sólo valores 0 o mayores a la siguiente capa de la red.\n",
    "\n",
    "**Softmax** toma un conjunto de valores, y efectivamente escoge el más grande, así que, por ejemplo, si la salida de la última capa se ve como [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], te salva de pescar a través de ella buscando el valor más grande, y la convierte en [0,0,0,0,1,0,0,0,0,0] -- ¡El objetivo es salvar un montón de codificación!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import errno\n",
    "import pydot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurar el modelo\n",
    "\n",
    "Lo siguiente que hay que hacer, ahora que el modelo está definido, es construirlo realmente. Esto se hace compilándolo con una función de optimización y pérdida como antes -- y luego lo entrena llamando a **model.fit** pidiéndole que ajuste los datos de su entrenamiento a sus etiquetas de entrenamiento -- es decir, que averigüe la relación entre los datos de entrenamiento y sus etiquetas reales, de modo que en el futuro si tiene datos que se parecen a los datos de entrenamiento, entonces puede hacer una predicción de cómo se verían esos datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=[('accuracy')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que haya terminado el entrenamiento... deberías ver un valor de precisión al final de la última época. Podría parecer algo como 0,9098. Esto te dice que tu red neural tiene una precisión del 91% en la clasificación de los datos de entrenamiento. Es decir, calculó una coincidencia de patrón entre la imagen y las etiquetas que funcionó el 91% de las veces. No es genial, pero no está mal considerando que sólo fue entrenado durante 5 épocas y se hizo bastante rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Pero cómo funcionaría con datos no vistos? Por eso tenemos las imágenes de prueba. Podemos llamar a model.evaluate, y pasar en los dos conjuntos, y se informará de la pérdida para cada uno. Vamos a intentarlo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mí, eso arrojó una precisión de alrededor de 0,8838, lo que significa que fue de alrededor del 88% de exactitud. Como era de esperar, probablemente no le iría tan bien con datos no vistos como con los datos en los que fue entrenado.  A medida que avance en este curso, verá formas de mejorarlo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    " \n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    " \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                         100*np.max(predictions_array),\n",
    "                                         class_names[true_label]),\n",
    "                                         color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array, true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array, color=\"#007700\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    \n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 8\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, predictions[i], test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, predictions[i],  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted label, and the true label\n",
    "# Color correct predictions in blue, incorrect predictions in red\n",
    "num_rows = 7\n",
    "num_cols = 2\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, predictions[i], test_labels, test_images)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, predictions[i], test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejorar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
    "model.add(keras.layers.Dense(10, activation='sigmoid'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=[('accuracy')])\n",
    "\n",
    "model.fit(training_images, training_labels, epochs=5)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels);\n",
    "print('\\nTest accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias generales\n",
    "\n",
    "- [Deep Learning en Wikipedia](https://es.wikipedia.org/wiki/Aprendizaje_profundo)\n",
    "- [Perceptrón](hhttps://es.wikipedia.org/wiki/Perceptr%C3%B3n)\n",
    "- [MLP](https://es.wikipedia.org/wiki/Perceptr%C3%B3n_multicapa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
